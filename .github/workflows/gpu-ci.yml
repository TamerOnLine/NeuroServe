name: GPU Test (Windows self-hosted)

on:
  push:
  workflow_dispatch:

jobs:
  test-gpu:
    runs-on: [self-hosted, gpu]   # Only on your GPU self-hosted runner
    defaults:
      run:
        shell: cmd                # Important: avoid PowerShell (restricted by ExecutionPolicy)

    env:
      DEVICE: cuda:0
      CI_LIGHT_MODE: "0"          # On GPU we want to actually load the model

    steps:
      - uses: actions/checkout@v4

      - name: Show GPU info
        run: nvidia-smi

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Start server (background)
        run: |
          rem Start Uvicorn in the background using PowerShell, but bypass ExecutionPolicy only locally
          powershell -ExecutionPolicy Bypass -NoProfile -NonInteractive -Command ^
            "$p = Start-Process python -ArgumentList '-m','uvicorn','app.main:app','--host','127.0.0.1','--port','8000','--no-access-log','--log-level','info' -PassThru; ^
             Set-Content -Path uvicorn.pid -Value $p.Id; ^
             Write-Host ('Started PID: ' + $p.Id)"

      - name: Wait for /health (up to 180s)
        run: |
          for /l %%I in (1,1,180) do (
            curl -fsS http://127.0.0.1:8000/health >NUL 2>&1 && (
              echo Server is up ✓
              goto :ok
            )
            echo Waiting... (%%I)
            timeout /t 1 /nobreak >NUL
          )
          echo Server did not start ✗
          if exist server.log type server.log
          exit /b 1
          :ok

      - name: Run tests
        run: python -m scripts.test_api

      - name: Stop server
        if: always()
        run: |
          if exist uvicorn.pid (
            for /f %%P in (uvicorn.pid) do taskkill /PID %%P /F >NUL 2>&1
          )

      - name: Upload server.log (on failure)
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: server-log-gpu
          path: server.log
          if-no-files-found: ignore
